{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import skorch\n",
    "from skorch.helper import predefined_split\n",
    "from skorch import NeuralNetBinaryClassifier\n",
    "from skorch.callbacks import EarlyStopping, Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>__rangexy</th>\n",
       "      <th>Noise</th>\n",
       "      <th>Normal change rate</th>\n",
       "      <th>Number of neighbors</th>\n",
       "      <th>Surface density</th>\n",
       "      <th>Omnivariance</th>\n",
       "      <th>Eigenentropy</th>\n",
       "      <th>Anisotropy</th>\n",
       "      <th>Planarity</th>\n",
       "      <th>Linearity</th>\n",
       "      <th>Surface variation</th>\n",
       "      <th>Sphericity</th>\n",
       "      <th>Verticality</th>\n",
       "      <th>3rd eigenvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.286</td>\n",
       "      <td>2.673</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>4.236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010093</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1251.594482</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.259228</td>\n",
       "      <td>0.986132</td>\n",
       "      <td>0.346270</td>\n",
       "      <td>0.639862</td>\n",
       "      <td>0.010093</td>\n",
       "      <td>0.013868</td>\n",
       "      <td>0.056737</td>\n",
       "      <td>0.000840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.419</td>\n",
       "      <td>2.662</td>\n",
       "      <td>-0.938</td>\n",
       "      <td>4.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011580</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>1796.540894</td>\n",
       "      <td>0.013134</td>\n",
       "      <td>0.292883</td>\n",
       "      <td>0.982632</td>\n",
       "      <td>0.465111</td>\n",
       "      <td>0.517521</td>\n",
       "      <td>0.011580</td>\n",
       "      <td>0.017368</td>\n",
       "      <td>0.064407</td>\n",
       "      <td>0.001123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.592</td>\n",
       "      <td>2.680</td>\n",
       "      <td>-0.886</td>\n",
       "      <td>4.482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011959</td>\n",
       "      <td>1861.0</td>\n",
       "      <td>2369.498779</td>\n",
       "      <td>0.015455</td>\n",
       "      <td>0.322546</td>\n",
       "      <td>0.980218</td>\n",
       "      <td>0.614534</td>\n",
       "      <td>0.365685</td>\n",
       "      <td>0.011959</td>\n",
       "      <td>0.019782</td>\n",
       "      <td>0.070589</td>\n",
       "      <td>0.001316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.105</td>\n",
       "      <td>0.585</td>\n",
       "      <td>-0.767</td>\n",
       "      <td>3.160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.063361</td>\n",
       "      <td>526.0</td>\n",
       "      <td>669.723999</td>\n",
       "      <td>0.011130</td>\n",
       "      <td>0.191430</td>\n",
       "      <td>0.911196</td>\n",
       "      <td>0.223945</td>\n",
       "      <td>0.687251</td>\n",
       "      <td>0.063361</td>\n",
       "      <td>0.088804</td>\n",
       "      <td>0.003578</td>\n",
       "      <td>0.003264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.253</td>\n",
       "      <td>-0.561</td>\n",
       "      <td>-0.802</td>\n",
       "      <td>3.301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.048970</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>1611.921265</td>\n",
       "      <td>0.013326</td>\n",
       "      <td>0.224003</td>\n",
       "      <td>0.926413</td>\n",
       "      <td>0.355537</td>\n",
       "      <td>0.570876</td>\n",
       "      <td>0.048970</td>\n",
       "      <td>0.073587</td>\n",
       "      <td>0.043278</td>\n",
       "      <td>0.003103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       X      Y      Z  __rangexy  Noise  Normal change rate  \\\n",
       "0  3.286  2.673 -0.996      4.236    1.0            0.010093   \n",
       "1  3.419  2.662 -0.938      4.333    1.0            0.011580   \n",
       "2  3.592  2.680 -0.886      4.482    1.0            0.011959   \n",
       "3  3.105  0.585 -0.767      3.160    1.0            0.063361   \n",
       "4  3.253 -0.561 -0.802      3.301    1.0            0.048970   \n",
       "\n",
       "   Number of neighbors  Surface density  Omnivariance  Eigenentropy  \\\n",
       "0                983.0      1251.594482      0.010354      0.259228   \n",
       "1               1411.0      1796.540894      0.013134      0.292883   \n",
       "2               1861.0      2369.498779      0.015455      0.322546   \n",
       "3                526.0       669.723999      0.011130      0.191430   \n",
       "4               1266.0      1611.921265      0.013326      0.224003   \n",
       "\n",
       "   Anisotropy  Planarity  Linearity  Surface variation  Sphericity  \\\n",
       "0    0.986132   0.346270   0.639862           0.010093    0.013868   \n",
       "1    0.982632   0.465111   0.517521           0.011580    0.017368   \n",
       "2    0.980218   0.614534   0.365685           0.011959    0.019782   \n",
       "3    0.911196   0.223945   0.687251           0.063361    0.088804   \n",
       "4    0.926413   0.355537   0.570876           0.048970    0.073587   \n",
       "\n",
       "   Verticality  3rd eigenvalue  \n",
       "0     0.056737        0.000840  \n",
       "1     0.064407        0.001123  \n",
       "2     0.070589        0.001316  \n",
       "3     0.003578        0.003264  \n",
       "4     0.043278        0.003103  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: Normal change rate, Number of neighbors, Surface density, Omnivariance, Eigenentropy, Anisotropy, Planarity, Linearity, Surface variation, Sphericity, Verticality, 3rd eigenvalue\n",
      "Class Labels  Noise\n",
      "Non-Noise Points: 102577/105815 (0.969%)\n",
      "Noise Points:3238/105815 (0.031%)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/labeled_snowy_5.csv\")\n",
    "\n",
    "display(df.head(5))\n",
    "\n",
    "columns = df.columns[4:]\n",
    "\n",
    "x_labels = columns[1:]\n",
    "y_labels = columns[0]\n",
    "\n",
    "print(\"Input features: \", end=\"\")\n",
    "print(*x_labels, sep=\", \")\n",
    "print(\"Class Labels \", y_labels)\n",
    "\n",
    "\n",
    "data = df[columns].values.astype(np.float32)\n",
    "\n",
    "noise_indices = np.where(data[:,0] == 1)[0]\n",
    "real_indices = np.where(data[:,0] == 0)[0]\n",
    "\n",
    "np.random.shuffle(noise_indices)\n",
    "np.random.shuffle(real_indices)\n",
    "\n",
    "\n",
    "x_test_indices = np.concatenate((noise_indices[:250], real_indices[:2000]))\n",
    "x_val_indices = np.concatenate((noise_indices[250:500], real_indices[2000:4000]))\n",
    "x_train_indices = np.concatenate((noise_indices[500:], real_indices[4000:]))\n",
    "\n",
    "\n",
    "x_train = data[x_train_indices, 1:]\n",
    "y_train = data[x_train_indices, 0]\n",
    "\n",
    "x_val = data[x_val_indices, 1:]\n",
    "y_val = data[x_val_indices, 0]\n",
    "\n",
    "val_ds = TensorDataset(torch.tensor(x_val), torch.tensor(y_val))\n",
    "\n",
    "x_test = data[x_test_indices, 1:]\n",
    "y_test = data[x_test_indices, 0]\n",
    "\n",
    "total_points = len(data)\n",
    "positive_points = len(noise_indices)\n",
    "\n",
    "print(f\"Non-Noise Points: {total_points - positive_points}/{total_points} ({(total_points - positive_points)/total_points:.3f}%)\")\n",
    "print(f\"Noise Points:{positive_points}/{total_points} ({positive_points/total_points:.3f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Noise_Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, dropout=0.03):\n",
    "        super(Noise_Classifier, self).__init__()\n",
    "        layers = []\n",
    "        activation = nn.Tanh\n",
    "        for i in range(num_layers):\n",
    "            if i == 0:\n",
    "                layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "                layers.append(activation())\n",
    "            elif i == num_layers - 1:\n",
    "                layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "            else:\n",
    "                layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "                layers.append(activation())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.0820\u001b[0m       \u001b[32m0.9627\u001b[0m        \u001b[35m0.1825\u001b[0m  2.5301\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = './Model_Checkpoints/'\n",
    "\n",
    "callbacks = [EarlyStopping(patience=20, threshold=0.001, threshold_mode='abs', monitor='valid_acc', lower_is_better=False),\n",
    "            #Checkpoint(monitor='valid_acc_best', f_params='NoiseClassifier.pt', dirname=checkpoint_dir)\n",
    "]\n",
    "optimizer = optim.Adam\n",
    "net = NeuralNetBinaryClassifier(\n",
    "    Noise_Classifier,\n",
    "    train_split=predefined_split(val_ds),\n",
    "    module__input_dim=x_train.shape[1],\n",
    "    module__output_dim=1,\n",
    "    module__hidden_dim=200,\n",
    "    module__num_layers=8,\n",
    "    module__dropout=0.000,\n",
    "    optimizer=optimizer,\n",
    "    optimizer__weight_decay=.00001,\n",
    "    max_epochs=200,\n",
    "    lr=5e-5,\n",
    "    batch_size=64,\n",
    "    device='cuda:0',\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__num_workers=2,\n",
    "    iterator_train__pin_memory=True,\n",
    "    iterator_valid__num_workers=2,\n",
    "    iterator_valid__pin_memory=True,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "net = net.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.992\n",
      "Validation Accuracy: 0.968\n",
      "Test Accuracy: 0.970\n"
     ]
    }
   ],
   "source": [
    "net.load_params(f_params=checkpoint_dir+'NoiseClassifier.pt', f_optimizer=checkpoint_dir + 'optimizer.pt', f_history=checkpoint_dir+'history.json')\n",
    "train_acc = net.score(x_train, y_train)\n",
    "val_acc = net.score(x_val, y_val)\n",
    "test_acc = net.score(x_test, y_test)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.3f}\")\n",
    "print(f\"Validation Accuracy: {val_acc:.3f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating New Data Set with Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = \"data/NN_predictions.csv\"\n",
    "\n",
    "prediction = net.predict(data[:, 1:])\n",
    "\n",
    "df['NN_Predictions'] = prediction\n",
    "\n",
    "new_df = df[['X', 'Y', 'Z', '__rangexy', 'Noise', 'NN_Predictions']]\n",
    "new_df.to_csv(destination, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
